/// <reference types="node" />
import { IGetToken } from 'token-types';
import { ReadStreamTokenizer } from "./ReadStreamTokenizer";
import { FileTokenizer } from "./FileTokenizer";
import * as stream from "stream";
/**
 * Used to reject read if end-of-stream or end-of-file is reached
 * @type {Error}
 */
export declare const EndOfFile: Error;
export interface ITokenizer {
    /**
     * File length in bytes
     */
    fileSize?: number;
    readBuffer(buffer: Buffer, offset: number, length: number, position?: number): Promise<number>;
    readToken<T>(token: IGetToken<T>, position?: number | null): Promise<T>;
    readNumber(token: IGetToken<number>): Promise<number>;
    /**
     * Ignore given number of bytes
     * @param length Lenght in bytes
     */
    ignore(length: number): any;
}
export declare class IgnoreType implements IGetToken<Buffer> {
    len: number;
    /**
     * @param len Number of bytes to ignore (skip)
     */
    constructor(len: number);
    get(buf: Buffer, off: number): Buffer;
}
/**
 * Construct ReadStreamTokenizer from given stream.
 * Will set fileSize, if provided given stream has set the .path property/
 * @param stream stream.Readable
 * @returns {Promise<ReadStreamTokenizer>}
 */
export declare function fromStream(stream: stream.Readable): Promise<ReadStreamTokenizer>;
/**
 * Construct ReadStreamTokenizer from given file path.
 * @param filePath
 * @returns {Promise<FileTokenizer>}
 */
export declare function fromFile(filePath: string): Promise<FileTokenizer>;
